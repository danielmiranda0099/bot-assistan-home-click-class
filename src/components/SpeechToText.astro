---
// SpeechToText.astro
---

<div class="speech-container">
  <button id="speech-button" class="speech-button" type="button">
    <svg
      width="24"
      height="24"
      viewBox="0 0 24 24"
      fill="currentColor"
      id="micIcon"
    >
      <path
        d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.48 6-3.3 6-6.72h-1.7z"
      ></path>
    </svg>
  </button>

  <div class="status-indicator">
    <span id="hold-to-speak" class="help-text">Hold To Speak</span>
    <br />
    <span id="status-text" class="status-text">Ready</span>
  </div>
</div>

<style>
  .speech-container {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 0.5rem;
    padding-bottom: 1rem;
    margin-top: -3rem;
  }

  .speech-button {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 0.5rem;
    user-select: none;

    width: 50px;
    height: 50px;
    border-radius: 50%;
    background: linear-gradient(135deg, #3b82f6, #10b981);
    border: none;
    color: white;
    cursor: pointer;
    transition: all 0.3s ease;
    position: relative;
    z-index: 5;
    box-shadow: 0 4px 20px rgba(59, 130, 246, 0.3);
  }

  .speech-button::before {
  content: '';
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  width: 100%;
  height: 100%;
  border-radius: inherit;
  background: linear-gradient(135deg, #3b82f6, #10b981);
  opacity: 0;
  pointer-events: none;
  z-index: -1;
}

  .speech-button.pulse-active::before {
    opacity: 0.6;
    animation: pulse-gradient-animation 1.6s infinite;
  }

  .speech-button.recording::before {
    animation: none;
    opacity: 0;
  }

  .speech-button:hover {
    transform: translateY(-2px);
    box-shadow: 0 8px 25px rgba(59, 130, 246, 0.3);
  }

  .speech-button:active {
    transform: translateY(0);
    background: linear-gradient(135deg, #1d4ed8 0%, #1e40af 100%);
  }

  .speech-button.recording {
    background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
    animation: pulse 1.5s ease-in-out infinite;
  }

  .speech-button.recording .button-text::after {
    content: "...";
    animation: dots 1.5s linear infinite;
  }

  .button-icon {
    font-size: 1.25rem;
  }

  .button-text {
    font-weight: 600;
  }

  .status-indicator {
    text-align: center;
  }

  .status-text, .help-text {
    font-size: 0.875rem;
    color: #6b7280;
    font-weight: 500;
  }

  .help-text{
    color: inherit;
  }

  .status-text.listening {
    color: #ef4444;
  }

  .status-text.processing {
    color: #f59e0b;
  }

  .status-text.ready {
    color: #10b981;
  }

  @keyframes pulse {
    0%,
    100% {
      box-shadow: 0 8px 25px rgba(239, 68, 68, 0.3);
    }
    50% {
      box-shadow: 0 8px 35px rgba(239, 68, 68, 0.5);
    }
  }

  @keyframes dots {
    0%,
    20% {
      content: "";
    }
    40% {
      content: ".";
    }
    60% {
      content: "..";
    }
    80%,
    100% {
      content: "...";
    }
  }

  .speech-button:disabled {
    background: linear-gradient(135deg, #b3b3b3, #c9c9c9);
    cursor: not-allowed;
    transform: none;
  }

  .speech-button:disabled:hover {
    transform: none;
    box-shadow: none;
  }
</style>

<script>
  interface SpeechRecognitionEvent extends Event {
    results: SpeechRecognitionResultList;
    resultIndex: number;
  }

  interface SpeechRecognitionErrorEvent extends Event {
    error: string;
    message: string;
  }

  interface SpeechRecognition extends EventTarget {
    continuous: boolean;
    interimResults: boolean;
    lang: string;
    start(): void;
    stop(): void;
    abort(): void;
    onaudiostart: ((this: SpeechRecognition, ev: Event) => void) | null;
    onaudioend: ((this: SpeechRecognition, ev: Event) => void) | null;
    onend: ((this: SpeechRecognition, ev: Event) => void) | null;
    onerror:
      | ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => void)
      | null;
    onresult:
      | ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => void)
      | null;
    onstart: ((this: SpeechRecognition, ev: Event) => void) | null;
  }

  declare global {
    interface Window {
      SpeechRecognition: {
        new (): SpeechRecognition;
      };
      webkitSpeechRecognition: {
        new (): SpeechRecognition;
      };
    }
  }

  import { AudioService } from '../stores/AudioService.ts';

  let currentIsAskState = false;
  const audioService = new AudioService();

  class SpeechToTextController {
    private recognition: SpeechRecognition | null = null;
    private isListening: boolean = false;
    private isPressed: boolean = false;
    private accumulatedText: string = "";

    constructor(
      private button: HTMLButtonElement,
      private input: HTMLTextAreaElement,
      private statusText: HTMLSpanElement
    ) {
      this.initializeSpeechRecognition();
      this.setupEventListeners();
    }

    private initializeSpeechRecognition(): void {
      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;

      console.log("Speech recognition support:", !!SpeechRecognition);

      if (!SpeechRecognition) {
        console.error("Speech recognition not supported in this browser");
        this.updateStatus("Speech recognition not supported", "error");
        this.button.disabled = true;
        return;
      }

      this.recognition = new SpeechRecognition();
      console.log("Speech recognition initialized");
      this.configureSpeechRecognition();
      this.setupSpeechEvents();
    }

    private configureSpeechRecognition(): void {
      if (!this.recognition) return;

      this.recognition.continuous = true;
      this.recognition.interimResults = true;
      this.recognition.lang = "en-US";
    }

    private setupSpeechEvents(): void {
      if (!this.recognition) return;

      this.recognition.onstart = () => {
        this.isListening = true;
        this.updateButtonState();
        this.updateStatus("Listening...", "listening");
      };

      this.recognition.onresult = (event: SpeechRecognitionEvent) => {
        this.handleSpeechResult(event);
      };

      this.recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
        this.handleSpeechError(event);
      };

      this.recognition.onend = () => {
        this.isListening = false;
        this.updateButtonState();

        if (this.isPressed) {
          this.startListening();
        } else {
          this.updateStatus("Ready", "ready");
        }
      };
    }

    private setupEventListeners(): void {
      this.button.addEventListener(
        "mousedown",
        this.handleMouseDown.bind(this)
      );
      this.button.addEventListener("mouseup", this.handleMouseUp.bind(this));
      this.button.addEventListener("mouseleave", this.handleMouseUp.bind(this));

      this.button.addEventListener(
        "touchstart",
        this.handleTouchStart.bind(this),
        { passive: false }
      );
      this.button.addEventListener("touchend", this.handleTouchEnd.bind(this));
      this.button.addEventListener(
        "touchcancel",
        this.handleTouchEnd.bind(this)
      );

      document.addEventListener("keydown", this.handleKeyDown.bind(this));
      document.addEventListener("keyup", this.handleKeyUp.bind(this));
    }

    private handleMouseDown(event: MouseEvent): void {
      if (event.button === 0) {
        this.startRecording();
      }
    }

    private handleMouseUp(): void {
      this.stopRecording();
    }

    private handleTouchStart(event: TouchEvent): void {
      event.preventDefault();
      this.startRecording();
    }

    private handleTouchEnd(): void {
      this.stopRecording();
    }

    private handleKeyDown(event: KeyboardEvent): void {
      if (
        event.code === "Space" &&
        !event.repeat &&
        document.activeElement === this.button
      ) {
        event.preventDefault();
        this.startRecording();
      }
    }

    private handleKeyUp(event: KeyboardEvent): void {
      if (event.code === "Space" && document.activeElement === this.button) {
        event.preventDefault();
        this.stopRecording();
      }
    }

    private startRecording(): void {
      if (this.isPressed || !this.recognition) return;

      this.isPressed = true;
      this.accumulatedText = this.input.value;
      this.button.classList.remove('pulse-active');
      this.startListening();
    }

    private stopRecording(): void {
      if (!this.isPressed) return;

      this.isPressed = false;
      this.stopListening();
      if (currentIsAskState) {
        setTimeout(() => {
          this.button.classList.add('pulse-active');
        }, 100);
      }
    }

    private startListening(): void {
      if (!this.recognition || this.isListening) return;

      try {
        this.recognition.start();
        audioService.play('microConnect');
      } catch (error) {
        console.error("Error starting speech recognition:", error);
        this.updateStatus("Error starting recognition", "error");
      }
    }

    private stopListening(): void {
      if (!this.recognition || !this.isListening) return;

      audioService.play('microDisconnect');
      this.recognition.stop();
    }

    private handleSpeechResult(event: SpeechRecognitionEvent): void {
      let finalTranscript = "";
      let interimTranscript = "";

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        const transcript = result[0].transcript;

        if (result.isFinal) {
          finalTranscript += transcript;
        } else {
          interimTranscript += transcript;
        }
      }

      if (finalTranscript) {
        // NUEVO: Concatenar texto final al texto acumulado
        this.accumulatedText +=
          (this.accumulatedText ? " " : "") + finalTranscript.trim();
        console.log("Final transcript:", finalTranscript.trim());
        console.log("Accumulated text:", this.accumulatedText);
        this.input.value = this.accumulatedText;
        this.updateStatus("Text captured", "ready");
      } else if (interimTranscript) {
        // NUEVO: Mostrar texto acumulado + texto interim (sin guardarlo aún)
        const previewText =
          this.accumulatedText +
          (this.accumulatedText ? " " : "") +
          interimTranscript.trim();
        console.log("Interim transcript:", interimTranscript.trim());
        this.input.value = previewText;
        this.updateStatus("Processing...", "processing");
      }
    }

    private handleSpeechError(event: SpeechRecognitionErrorEvent): void {
      console.error("Speech recognition error:", event.error);

      const errorMessages: Record<string, string> = {
        "no-speech": "No speech detected",
        "audio-capture": "Microphone access denied",
        "not-allowed": "Microphone permission denied",
        network: "Network error occurred",
        aborted: "Recognition aborted",
      };

      const message =
        errorMessages[event.error] || "Recognition error occurred";
      this.updateStatus(message, "error");
    }

    private updateButtonState(): void {
      const isActive = this.isListening && this.isPressed;
      this.button.classList.toggle("recording", isActive);
    }

    private updateStatus(
      message: string,
      type: "ready" | "listening" | "processing" | "error"
    ): void {
      this.statusText.textContent = message;
      this.statusText.className = `status-text ${type}`;
    }
  }

  // Initialize component when DOM is loaded
  document.addEventListener("DOMContentLoaded", () => {
    const button = document.getElementById(
      "speech-button"
    ) as HTMLButtonElement;
    const input = document.querySelector(
      ".text-input-container textarea"
    ) as HTMLTextAreaElement;
    const statusText = document.getElementById(
      "status-text"
    ) as HTMLSpanElement;

    console.log(
      "SpeechToText init - button:",
      button,
      "input:",
      input,
      "statusText:",
      statusText
    );

    if (button && input && statusText) {
      new SpeechToTextController(button, input, statusText);
    } else {
      console.error(
        "SpeechToText: Missing elements - button:",
        !!button,
        "input:",
        !!input,
        "statusText:",
        !!statusText
      );
    }
  });

  function updateSpeechButtonState(isAskState: boolean) {
    currentIsAskState = isAskState;
    const button = document.getElementById("speech-button") as HTMLButtonElement;
    if (button) {
      if (isAskState && !button.classList.contains('recording')) {
        button.classList.add('pulse-active');
      } else {
        button.classList.remove('pulse-active');
      }
    }
  }

  (window as any).updateSpeechButtonState = updateSpeechButtonState;
</script>
